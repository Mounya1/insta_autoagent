{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":14609425,"datasetId":9331727,"databundleVersionId":15445712}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\" Installing...\\n\")\n!pip install -q torch transformers\n!pip install -q llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu118\n!pip install -q diffusers accelerate  \n!pip install -q sentence-transformers cloudinary\n!pip install -q pandas numpy plotly Pillow requests\nprint(\"\\n Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T21:05:49.550224Z","iopub.execute_input":"2026-02-17T21:05:49.551011Z","iopub.status.idle":"2026-02-17T21:06:05.803154Z","shell.execute_reply.started":"2026-02-17T21:05:49.550981Z","shell.execute_reply":"2026-02-17T21:06:05.802245Z"}},"outputs":[{"name":"stdout","text":" Installing...\n\n\n Done!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"pip install pinecone","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:29:43.586427Z","iopub.execute_input":"2026-02-17T20:29:43.587062Z","iopub.status.idle":"2026-02-17T20:29:47.927543Z","shell.execute_reply.started":"2026-02-17T20:29:43.587025Z","shell.execute_reply":"2026-02-17T20:29:47.926850Z"}},"outputs":[{"name":"stdout","text":"Collecting pinecone\n  Downloading pinecone-8.0.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2026.1.4)\nRequirement already satisfied: orjson>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (3.11.3)\nCollecting pinecone-plugin-assistant<4.0.0,>=3.0.1 (from pinecone)\n  Downloading pinecone_plugin_assistant-3.0.2-py3-none-any.whl.metadata (30 kB)\nCollecting pinecone-plugin-interface<0.1.0,>=0.0.7 (from pinecone)\n  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from pinecone) (4.15.0)\nRequirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.6.3)\nCollecting packaging<25.0,>=24.2 (from pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (2.32.5)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (3.11)\nDownloading pinecone-8.0.1-py3-none-any.whl (736 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m736.8/736.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pinecone_plugin_assistant-3.0.2-py3-none-any.whl (280 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m280.9/280.9 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pinecone-plugin-interface, packaging, pinecone-plugin-assistant, pinecone\n  Attempting uninstall: packaging\n    Found existing installation: packaging 26.0rc2\n    Uninstalling packaging-26.0rc2:\n      Successfully uninstalled packaging-26.0rc2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.47.0 which is incompatible.\ngoogle-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\npylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed packaging-24.2 pinecone-8.0.1 pinecone-plugin-assistant-3.0.2 pinecone-plugin-interface-0.0.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os, torch, requests, pandas as pd, numpy as np, time, json, random\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict, Optional\nfrom datetime import datetime\nfrom PIL import Image\nfrom io import BytesIO\nimport cloudinary\nimport cloudinary.uploader\nfrom llama_cpp import Llama\nfrom diffusers import StableDiffusionXLPipeline\nfrom pinecone import Pinecone\nfrom sentence_transformers import SentenceTransformer\n\nimport logging\nlogging.basicConfig(level=logging.INFO, format='%(message)s')\nlogger = logging.getLogger(__name__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:32:17.702372Z","iopub.execute_input":"2026-02-17T20:32:17.702735Z","iopub.status.idle":"2026-02-17T20:33:15.177295Z","shell.execute_reply.started":"2026-02-17T20:32:17.702704Z","shell.execute_reply":"2026-02-17T20:33:15.176657Z"}},"outputs":[{"name":"stderr","text":"2026-02-17 20:32:53.112827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771360373.492675      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771360373.588922      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771360374.396113      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771360374.396145      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771360374.396148      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771360374.396150      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"@dataclass\nclass Config:\n    # Instagram tokens\n    PAGE_ACCESS_TOKEN: str = os.getenv(\"PAGE_ACCESS_TOKEN\", \"your_page_token_here\")\n\n    FACEBOOK_PAGE_ID: str = os.getenv(\"FACEBOOK_PAGE_ID\", \"your_page_id\")\n    INSTAGRAM_USER_ID: str = os.getenv(\"INSTAGRAM_USER_ID\", \"your_user_id\")\n    \n    # Cloudinary\n    CLOUDINARY_CLOUD_NAME: str = os.getenv(\"CLOUDINARY_CLOUD_NAME\", \"your_cloud_name\")\n    CLOUDINARY_API_KEY: str = os.getenv(\"CLOUDINARY_API_KEY\", \"your_api_key\")\n    CLOUDINARY_API_SECRET: str = os.getenv(\"CLOUDINARY_API_SECRET\", \"your_api_secret\")\n    \n    # ‚ïê‚ïê‚ïê PINECONE ‚ïê‚ïê‚ïê\n    PINECONE_API_KEY: str = os.getenv(\"PINECONE_API_KEY\", \"your_pinecone_key\")\n    PINECONE_INDEX: str = os.getenv(\"PINECONE_INDEX\", \"autoagent\")\n    \n    # SDXL settings\n    SDXL_MODEL: str = \"stabilityai/stable-diffusion-xl-base-1.0\"\n    IMAGE_SIZE: int = 1024\n    NATIVE_RES: int = 1024\n    INFERENCE_STEPS: int = 30\n    GUIDANCE_SCALE: float = 7.5\n    IMAGE_DIR: str = \"/kaggle/working/instagram_images\"\n\n    \n    # LLaMA\n    LLAMA_MODEL_PATH: str = \"/kaggle/input/model-llama/llama-2-7b-chat.Q4_K_M.gguf\"\n    \n    # Brand\n    BRAND_NAME: str = \"ShopSmart\"\n    BRAND_HASHTAGS: List[str] = field(default_factory=lambda: [\"#ShopSmart\", \"#SmartShopping\"])\n    \n    # Budget\n    MONTHLY_POST_GOAL: int = 60\n    MONTHLY_BUDGET: float = 500.00\n    COST_PER_POST: float = 5.00\n    \n    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nconfig = Config()\nos.makedirs(config.IMAGE_DIR, exist_ok=True)\n\nprint(f\"Device: {config.DEVICE}\")\nprint(f\"Model: {config.SDXL_MODEL}\")\nprint(f\"Resolution: {config.IMAGE_SIZE}x{config.IMAGE_SIZE}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:42:34.226611Z","iopub.execute_input":"2026-02-17T20:42:34.226928Z","iopub.status.idle":"2026-02-17T20:42:34.235833Z","shell.execute_reply.started":"2026-02-17T20:42:34.226900Z","shell.execute_reply":"2026-02-17T20:42:34.235086Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nModel: stabilityai/stable-diffusion-xl-base-1.0\nResolution: 1024x1024\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(\" Loading products...\")\nr = requests.get(\"https://fakestoreapi.com/products\", timeout=15)\nproducts_df = pd.DataFrame(r.json())\nprint(f\" {len(products_df)} products\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:37:52.180870Z","iopub.execute_input":"2026-02-17T20:37:52.181243Z","iopub.status.idle":"2026-02-17T20:37:52.356474Z","shell.execute_reply.started":"2026-02-17T20:37:52.181214Z","shell.execute_reply":"2026-02-17T20:37:52.355793Z"}},"outputs":[{"name":"stdout","text":" Loading products...\n 20 products\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"class KnowledgeBase:\n    def __init__(self, config):\n        self.config = config\n        try:\n            print(\"\\n  Pinecone...\")\n            self.encoder = SentenceTransformer('all-MiniLM-L6-v2', device=config.DEVICE)\n            pc = Pinecone(api_key=config.PINECONE_API_KEY)\n            if config.PINECONE_INDEX not in pc.list_indexes().names():\n                pc.create_index(name=config.PINECONE_INDEX, dimension=384, metric='cosine',\n                              spec=ServerlessSpec(cloud='aws', region='us-east-1'))\n                time.sleep(10)\n            self.index = pc.Index(config.PINECONE_INDEX)\n            print(\" Ready\")\n        except:\n            print(\"  Pinecone unavailable\")\n            self.index = None\n    \n    def get_brand_context(self):\n        return f\"Brand: {self.config.BRAND_NAME}. Voice: {self.config.BRAND_VOICE}\"\n\nkb = KnowledgeBase(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:39:23.114067Z","iopub.execute_input":"2026-02-17T20:39:23.114778Z","iopub.status.idle":"2026-02-17T20:39:27.707483Z","shell.execute_reply.started":"2026-02-17T20:39:23.114725Z","shell.execute_reply":"2026-02-17T20:39:27.706737Z"}},"outputs":[{"name":"stdout","text":"\n  Pinecone...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc2fcee01ac1434db24733b272d60903"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91771012d18c48558a4bf21dd75a15e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92feb663d50847fb99191ca3f0f6fac9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01dee73c8a314ac8b1adea4ffbb8a51d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7781a5532a8d491193373a6d082623ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4c747f789624b569c512ea50f907083"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fda0342da5724ee3bfce0941b5383c36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f216e914a2c4b03ad7a29975d619d95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2ac7b88ab342c3b9e5528fc27f5903"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ff7699f3c2a455186d6f87eea4c0b1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6b18ab28021490d9eeffc4403454919"}},"metadata":{}},{"name":"stdout","text":" Ready\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class LLaMACaptionGenerator:\n    def __init__(self, config, kb):\n        self.config = config\n        self.kb = kb\n        self.llm = None\n\n        if os.path.exists(config.LLAMA_MODEL_PATH):\n            try:\n                from llama_cpp import Llama\n                print(\"\\n LLaMA 2...\")\n                self.llm = Llama(\n                    model_path=config.LLAMA_MODEL_PATH, n_ctx=2048,\n                    n_gpu_layers=35 if config.DEVICE == \"cuda\" else 0,\n                    verbose=False\n                )\n                print(\" Ready\")\n            except:\n                pass\n\n    # ‚îÄ‚îÄ public ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    def generate(self, product):\n        if self.llm:\n            caption = self._llama_generate(product)\n        else:\n            caption = self._template_generate(product)\n        hashtags = self._generate_hashtags(product)\n        return f\"{caption}\\n\\n{hashtags}\"\n\n    # ‚îÄ‚îÄ strip meta-commentary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    @staticmethod\n    def _clean(raw):\n        \"\"\"\n        Kills every pattern LLaMA actually outputs:\n\n        Case A ‚Äî multi-line, meta line on top:\n            Sure! Here's a caption...\n            üíé Shine bright...          ‚Üê we want this\n\n        Case B ‚Äî single line, meta + caption joined by colon:\n            Sure, here's a caption for ShopSmart's Ring: üíé Shine bright...\n                                                         ^^^^^^^^^^^^^^^^^ we want this\n\n        Case C ‚Äî label prefix:\n            Caption: üíé Shine bright...\n\n        Case D ‚Äî already clean:\n            üíé Shine bright...          ‚Üê pass through\n        \"\"\"\n        text = raw.strip()\n        if not text:\n            return \"\"\n\n        bad_starts = (\n            \"sure\", \"here\", \"caption:\", \"post:\", \"output:\",\n            \"result:\", \"instagram\", \"below\", \"check\", \"i've\",\n            \"i have\", \"let me\", \"for shopsmart\", \"for the\",\n            \"ok\", \"great\", \"perfect\"\n        )\n\n        # ‚îÄ‚îÄ Case B / C: single-line with colon before the real caption ‚îÄ‚îÄ\n        # Find the LAST colon that is followed by an emoji or newline\n        # e.g. \"Sure, here's ... ShopSmart's Ring: üíé ...\"\n        #                                          ^ split here\n        if text.lower().startswith(tuple(bad_starts)):\n            # walk through every colon; take the segment after the last one\n            # that still has meaningful content\n            parts = text.split(\":\")\n            for i in range(len(parts) - 1, 0, -1):\n                candidate = \":\".join(parts[i:]).strip()\n                if len(candidate) > 20:          # something real after it\n                    text = candidate\n                    break\n            else:\n                # no colon split worked ‚Üí entire line is junk\n                return \"\"\n\n        # ‚îÄ‚îÄ Case A: multi-line, drop bad leading lines ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n        lines = [l.strip() for l in text.split(\"\\n\")]\n        cleaned = []\n        header_done = False\n        for line in lines:\n            if not header_done:\n                if not line:\n                    continue\n                if line.lower().startswith(tuple(bad_starts)):\n                    continue\n                if line.lower().rstrip(\":\") in (\"caption\", \"post\", \"output\", \"result\"):\n                    continue\n                header_done = True\n            cleaned.append(line)\n\n        result = \"\\n\".join(cleaned).strip()\n\n        # ‚îÄ‚îÄ final safety net ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n        if result.lower().startswith(tuple(bad_starts)):\n            return \"\"\n        return result\n\n    # ‚îÄ‚îÄ LLaMA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    def _llama_generate(self, product):\n        prompt = (\n            \"[INST]\\n\"\n            \"###EXAMPLE1###\\n\"\n            \"Product: AirPods Pro 2nd Gen\\n\"\n            \"Price: $249\\n\"\n            \"Rating: 4.8/5 (3200 reviews)\\n\"\n            \"Description: Next-gen noise cancellation with adaptive transparency.\\n\"\n            \"Caption:\\n\"\n            \"üéß Sound like never before.\\n\\n\"\n            \"AirPods Pro 2 ‚Äî adaptive noise cancellation\\n\"\n            \"that actually works. Loved by 3200+ buyers.\\n\\n\"\n            \"‚≠ê 4.8/5 | üí∞ $249\\n\\n\"\n            \"üëâ Link in bio ‚Äî grab yours today!\\n\"\n            \"###END###\\n\\n\"\n\n            \"###EXAMPLE2###\\n\"\n            \"Product: Nike Air Max 90\\n\"\n            \"Price: $129\\n\"\n            \"Rating: 4.5/5 (890 reviews)\\n\"\n            \"Description: Classic silhouette with visible Air cushioning.\\n\"\n            \"Caption:\\n\"\n            \"üî• The classic is back.\\n\\n\"\n            \"Nike Air Max 90 ‚Äî iconic style meets\\n\"\n            \"serious comfort. 890+ people agree.\\n\\n\"\n            \"‚≠ê 4.5/5 | üí∞ $129\\n\\n\"\n            \"üõí Shop now ‚Äî link in bio!\\n\"\n            \"###END###\\n\\n\"\n\n            f\"###NOW###\\n\"\n            f\"Product: {product['title']}\\n\"\n            f\"Price: ${product['price']}\\n\"\n            f\"Rating: {product['rating']['rate']}/5 ({product['rating']['count']} reviews)\\n\"\n            f\"Description: {product['description'][:150]}\\n\"\n            f\"Caption:\\n\"\n            \"[/INST]\"\n        )\n\n        try:\n            out = self.llm(\n                prompt, max_tokens=200, temperature=0.7,\n                stop=[\"###\", \"[INST]\", \"Product:\"]\n            )\n            raw = out[\"choices\"][0][\"text\"].strip()\n            caption = self._clean(raw)\n            return caption if caption else self._template_generate(product)\n        except:\n            return self._template_generate(product)\n\n    # ‚îÄ‚îÄ templates (fallback) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    def _template_generate(self, product):\n        title  = product[\"title\"]\n        price  = product[\"price\"]\n        rating = product[\"rating\"][\"rate\"]\n        count  = product[\"rating\"][\"count\"]\n        desc   = product[\"description\"][:100]\n\n        templates = {\n            \"electronics\": (\n                f\"‚ö° {title}\\n\\n\"\n                f\"{desc}\\n\\n\"\n                f\"Loved by {count}+ buyers. ‚≠ê {rating}/5\\n\"\n                f\"üí∞ Only ${price}\\n\\n\"\n                f\"üõí Shop now ‚Äî link in bio!\"\n            ),\n            \"jewelery\": (\n                f\"‚ú® {title}\\n\\n\"\n                f\"Timeless elegance. Stunning detail.\\n\"\n                f\"Loved by {count}+ customers. ‚≠ê {rating}/5\\n\"\n                f\"üíé Just ${price}\\n\\n\"\n                f\"üëâ Grab yours ‚Äî link in bio!\"\n            ),\n            \"men's clothing\": (\n                f\"üî• {title}\\n\\n\"\n                f\"Upgrade your wardrobe today.\\n\"\n                f\"{count}+ reviews. ‚≠ê {rating}/5\\n\"\n                f\"üí∞ Only ${price}\\n\\n\"\n                f\"üõí Shop now ‚Äî link in bio!\"\n            ),\n            \"women's clothing\": (\n                f\"üëó {title}\\n\\n\"\n                f\"Style that turns heads.\\n\"\n                f\"{count}+ reviews. ‚≠ê {rating}/5\\n\"\n                f\"üí∞ Just ${price}\\n\\n\"\n                f\"üõçÔ∏è Shop now ‚Äî link in bio!\"\n            ),\n        }\n        return templates.get(product[\"category\"], templates[\"electronics\"])\n\n    # ‚îÄ‚îÄ hashtags ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    def _generate_hashtags(self, product):\n        base = {\n            \"electronics\":       [\"#Tech\", \"#Gadgets\", \"#Electronics\", \"#TechDeals\"],\n            \"jewelery\":          [\"#Jewelry\", \"#JewelryLover\", \"#Accessories\", \"#GoldJewelry\"],\n            \"men's clothing\":   [\"#MensFashion\", \"#MensStyle\", \"#OOTD\", \"#MensWear\"],\n            \"women's clothing\": [\"#WomensFashion\", \"#WomensStyle\", \"#OOTD\", \"#Fashion\"],\n        }\n        tags = list(self.config.BRAND_HASHTAGS)\n        tags.extend(base.get(product[\"category\"], [\"#Shopping\", \"#OnlineShopping\"]))\n        tags.extend([\"#Sale\", \"#ShopNow\", \"#NewArrival\", \"#Limited\"])\n        return \" \".join(tags[:12])\n\ncaption_gen = LLaMACaptionGenerator(config, kb)\nprint(\" Caption generator ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:45:26.915214Z","iopub.execute_input":"2026-02-17T20:45:26.915800Z","iopub.status.idle":"2026-02-17T20:45:26.932161Z","shell.execute_reply.started":"2026-02-17T20:45:26.915770Z","shell.execute_reply":"2026-02-17T20:45:26.931401Z"}},"outputs":[{"name":"stdout","text":" Caption generator ready\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"class SDXLImageGenerator:\n    def __init__(self, config):\n        self.config = config\n        self.pipe = None\n        \n        if config.DEVICE == \"cuda\":\n            try:\n                print(\"Loading SDXL...\")\n                self.pipe = StableDiffusionXLPipeline.from_pretrained(\n                    config.SDXL_MODEL,\n                    torch_dtype=torch.float16,\n                    variant=\"fp16\",\n                    use_safetensors=True\n                )\n                self.pipe.to(config.DEVICE)\n                \n                try:\n                    self.pipe.enable_xformers_memory_efficient_attention()\n                except:\n                    self.pipe.enable_attention_slicing(1)\n                \n                try:\n                    self.pipe.enable_vae_slicing()\n                except:\n                    pass\n                \n                print(\"SDXL ready\")\n            except Exception as e:\n                print(f\"SDXL failed: {e}\")\n                self.pipe = None\n    \n    def create(self, product, pid):\n        if self.pipe:\n            try:\n                return self._generate(product, pid)\n            except Exception as e:\n                print(f\"Generation failed: {e}\")\n        return self._download_fallback(product, pid)\n    \n    def _generate(self, product, pid):\n        print(\"Generating...\")\n        title = product[\"title\"]\n        category = product[\"category\"]\n        \n        prompts = {\n            \"electronics\": f\"a {title} product on white background, studio lighting, professional product photo\",\n            \"jewelery\": f\"a {title} on dark velvet, soft golden light, luxury product photo\",\n            \"men's clothing\": f\"a {title} laid flat on white surface, studio lighting, professional photo\",\n            \"women's clothing\": f\"a {title} laid flat on white surface, soft natural light, professional photo\"\n        }\n        \n        prompt = prompts.get(category, f\"a {title} product on white background, studio lighting\")\n        \n        negative = \"person, people, human, face, hands, text, letters, watermark, logo, blurry\"\n        \n        image = self.pipe(\n            prompt=prompt,\n            negative_prompt=negative,\n            num_inference_steps=self.config.INFERENCE_STEPS,\n            guidance_scale=self.config.GUIDANCE_SCALE,\n            height=self.config.NATIVE_RES,\n            width=self.config.NATIVE_RES\n        ).images[0]\n        \n        image = image.resize((1080, 1080), Image.Resampling.LANCZOS)\n        path = os.path.join(self.config.IMAGE_DIR, f\"{pid}.png\")\n        image.save(path, \"PNG\", optimize=True)\n        print(f\"Done: {os.path.getsize(path)/1024:.1f}KB\")\n        return path\n    \n    def _download_fallback(self, product, pid):\n        try:\n            print(\"Downloading fallback image...\")\n            r = requests.get(product[\"image\"], timeout=30, headers={\"User-Agent\": \"Mozilla/5.0\"})\n            r.raise_for_status()\n            img = Image.open(BytesIO(r.content)).convert(\"RGB\")\n            canvas = Image.new(\"RGB\", (1080, 1080), (255, 255, 255))\n            img.thumbnail((1080, 1080), Image.Resampling.LANCZOS)\n            canvas.paste(img, ((1080 - img.width) // 2, (1080 - img.height) // 2))\n            path = os.path.join(self.config.IMAGE_DIR, f\"{pid}.jpg\")\n            canvas.save(path, \"JPEG\", quality=95)\n            print(f\"Fallback: {os.path.getsize(path)/1024:.1f}KB\")\n            return path\n        except Exception as e:\n            print(f\"Failed: {e}\")\n            return None\n\nimage_gen = SDXLImageGenerator(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:46:56.953076Z","iopub.execute_input":"2026-02-17T20:46:56.953951Z","iopub.status.idle":"2026-02-17T20:47:20.324255Z","shell.execute_reply.started":"2026-02-17T20:46:56.953909Z","shell.execute_reply":"2026-02-17T20:47:20.323217Z"}},"outputs":[{"name":"stdout","text":"Loading SDXL...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/609 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db28b682ec143c5b9abcd1a3c9da34c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 19 files:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e56b274dab84e6598bf4a71fe246048"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b8b12d3932543a6ab2bb64fa278d5c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb369e5079bc4cee9e9363e237d6c54d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee8d6d9a1dbd4dcf9c77fc6cd558cf83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf4bd4c1b310401ab8478971cd02f82e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28c41856ca934aa2ad002cccfd631718"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5de374855db84fc1a4e493b268b4581e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d153eee71b04f729624283497d75330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a83a96025924c7e8cf91011eed27d11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder_2/model.fp16.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17d758cd17c54192af07e2e6f60e3b5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2f59067943f49248b34e49d2d767d8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09d020cda5f6400eb3507232d1a01bfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5addb693eb44881975440c5c6bd9702"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf7071e196b24265a637d8713d2764bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/diffusion_pytorch_model.fp16.safete(‚Ä¶):   0%|          | 0.00/5.14G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c6b185236a841b08ea318edfac9c591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/diffusion_pytorch_model.fp16.safeten(‚Ä¶):   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2daffd6cdbb840e0989b51cc1db6667f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae_1_0/diffusion_pytorch_model.fp16.saf(‚Ä¶):   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40020b6844684a80b8534bdc81f3f4d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cbdc84a9f4842ed9aad04a98c9af788"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"name":"stdout","text":"SDXL ready\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"class BudgetManager:\n    def __init__(self, config):\n        self.config = config\n        self.posts_this_month = 0\n        self.spent = 0.0\n    \n    def can_post(self):\n        if self.posts_this_month >= self.config.MONTHLY_POST_GOAL:\n            return False, \"Monthly goal reached\"\n        if self.spent + self.config.COST_PER_POST > self.config.MONTHLY_BUDGET:\n            return False, \"Budget exceeded\"\n        return True, \"OK\"\n    \n    def record_post(self):\n        self.posts_this_month += 1\n        self.spent += self.config.COST_PER_POST\n    \n    def get_status(self):\n        return f\"Posts: {self.posts_this_month}/{self.config.MONTHLY_POST_GOAL} | Spent: ${self.spent:.2f}/${self.config.MONTHLY_BUDGET}\"\n\nbudget_manager = BudgetManager(config)\nprint(budget_manager.get_status())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:47:36.513870Z","iopub.execute_input":"2026-02-17T20:47:36.514568Z","iopub.status.idle":"2026-02-17T20:47:36.520148Z","shell.execute_reply.started":"2026-02-17T20:47:36.514540Z","shell.execute_reply":"2026-02-17T20:47:36.519578Z"}},"outputs":[{"name":"stdout","text":"Posts: 0/60 | Spent: $0.00/$500.0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"cloudinary.config(\n    cloud_name=config.CLOUDINARY_CLOUD_NAME,\n    api_key=config.CLOUDINARY_API_KEY,\n    api_secret=config.CLOUDINARY_API_SECRET\n)\nprint(\"Cloudinary configured\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:47:48.057041Z","iopub.execute_input":"2026-02-17T20:47:48.057384Z","iopub.status.idle":"2026-02-17T20:47:48.061795Z","shell.execute_reply.started":"2026-02-17T20:47:48.057353Z","shell.execute_reply":"2026-02-17T20:47:48.060910Z"}},"outputs":[{"name":"stdout","text":"Cloudinary configured\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"class InstagramAPI:\n    def __init__(self, config):\n        self.config = config\n        self.base = \"https://graph.facebook.com/v24.0\"\n        self.posted = []\n    \n    def post(self, url, caption, product):\n        try:\n            print(\"Posting to Instagram...\")\n            r1 = requests.post(\n                f\"{self.base}/{self.config.INSTAGRAM_USER_ID}/media\",\n                params={\n                    'image_url': url,\n                    'caption': caption[:2200],\n                    'access_token': self.config.PAGE_ACCESS_TOKEN\n                }\n            )\n            \n            if r1.status_code != 200:\n                return self._simulate(url, caption, product)\n            \n            cid = r1.json()['id']\n            print(f\"Container: {cid}\")\n            time.sleep(10)\n            \n            r2 = requests.post(\n                f\"{self.base}/{self.config.INSTAGRAM_USER_ID}/media_publish\",\n                params={'creation_id': cid, 'access_token': self.config.PAGE_ACCESS_TOKEN}\n            )\n            \n            if r2.status_code != 200:\n                return self._simulate(url, caption, product)\n            \n            mid = r2.json()['id']\n            post = {\n                'id': mid,\n                'status': 'published',\n                'engagement': np.random.uniform(0.03, 0.06),\n                'product': product['title'],\n                'time': datetime.now().isoformat()\n            }\n            self.posted.append(post)\n            return post\n        except:\n            return self._simulate(url, caption, product)\n    \n    def _simulate(self, url, caption, product):\n        post = {\n            'id': f\"sim_{int(time.time())}\",\n            'status': 'simulated',\n            'engagement': np.random.uniform(0.03, 0.06),\n            'product': product['title'],\n            'time': datetime.now().isoformat()\n        }\n        self.posted.append(post)\n        return post\n\ninsta = InstagramAPI(config)\nprint(\"Instagram API ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:48:13.357264Z","iopub.execute_input":"2026-02-17T20:48:13.357908Z","iopub.status.idle":"2026-02-17T20:48:13.367233Z","shell.execute_reply.started":"2026-02-17T20:48:13.357872Z","shell.execute_reply":"2026-02-17T20:48:13.366445Z"}},"outputs":[{"name":"stdout","text":"Instagram API ready\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"print(\"Checking setup...\")\nprint(f\"Page ID: {config.FACEBOOK_PAGE_ID}\")\nprint(f\"IG User ID: {config.INSTAGRAM_USER_ID}\")\nprint(f\"Token: {config.PAGE_ACCESS_TOKEN[:20]}...\")\nprint(\"\\nReady to post!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:48:29.404560Z","iopub.execute_input":"2026-02-17T20:48:29.405338Z","iopub.status.idle":"2026-02-17T20:48:29.409761Z","shell.execute_reply.started":"2026-02-17T20:48:29.405307Z","shell.execute_reply":"2026-02-17T20:48:29.409165Z"}},"outputs":[{"name":"stdout","text":"Checking setup...\nPage ID: 966806373184726\nIG User ID: 17841415236594174\nToken: EAAUf7yytfZB0BQg1ang...\n\nReady to post!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"class Tier2_SDXL:\n    def __init__(self, products_df, caption_gen, image_gen, insta, budget_manager, config):\n        self.products_df = products_df\n        self.caption_gen = caption_gen\n        self.image_gen = image_gen\n        self.insta = insta\n        self.budget_manager = budget_manager\n        self.config = config\n    \n    def run(self, num_posts=3):\n        print(f\"\\nTier 2: {num_posts} posts\")\n        print(budget_manager.get_status())\n        print(\"=\"*60)\n        \n        success = 0\n        \n        for i in range(num_posts):\n            print(f\"\\nPost {i+1}/{num_posts}\")\n            print(\"-\"*60)\n            \n            can_post, msg = self.budget_manager.can_post()\n            if not can_post:\n                print(f\"Stopped: {msg}\")\n                break\n            \n            product = self.products_df.sample(1).iloc[0].to_dict()\n            print(f\"Product: {product['title'][:50]}\")\n            print(f\"Price: ${product['price']} | Rating: {product['rating']['rate']}‚≠ê\")\n            \n            caption = self.caption_gen.generate(product)\n            print(f\"\\nCaption: {caption[:100]}...\")\n            \n            pid = f\"tier2_{int(time.time())}_{i}\"\n            img = self.image_gen.create(product, pid)\n            if not img:\n                continue\n            \n            try:\n                result = cloudinary.uploader.upload(img, folder=\"instagram\")\n                url = result[\"secure_url\"]\n                print(\"Uploaded to Cloudinary\")\n            except Exception as e:\n                print(f\"Upload failed: {e}\")\n                continue\n            \n            post = self.insta.post(url, caption, product)\n            if post:\n                self.budget_manager.record_post()\n                success += 1\n                if post[\"status\"] == \"published\":\n                    print(f\"‚úÖ LIVE: https://www.instagram.com/p/{post['id']}/\")\n                else:\n                    print(f\"‚úÖ Simulated ({post['engagement']:.2%})\")\n            \n            if i < num_posts - 1:\n                time.sleep(5)\n        \n        print(\"\\n\" + \"=\"*60)\n        print(f\"Complete: {success}/{num_posts} posted\")\n        print(budget_manager.get_status())\n        print(\"=\"*60)\n\ntier2 = Tier2_SDXL(products_df, caption_gen, image_gen, insta, budget_manager, config)\nprint(\"Tier2 ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:48:47.431973Z","iopub.execute_input":"2026-02-17T20:48:47.432273Z","iopub.status.idle":"2026-02-17T20:48:47.441959Z","shell.execute_reply.started":"2026-02-17T20:48:47.432248Z","shell.execute_reply":"2026-02-17T20:48:47.441388Z"}},"outputs":[{"name":"stdout","text":"Tier2 ready\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Test single product\ntest_product = products_df.sample(1).iloc[0].to_dict()\nprint(f\"Test product: {test_product['title']}\")\ntest_caption = caption_gen.generate(test_product)\nprint(f\"Caption:\\n{test_caption}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:49:20.130790Z","iopub.execute_input":"2026-02-17T20:49:20.131483Z","iopub.status.idle":"2026-02-17T20:49:20.136489Z","shell.execute_reply.started":"2026-02-17T20:49:20.131451Z","shell.execute_reply":"2026-02-17T20:49:20.135726Z"}},"outputs":[{"name":"stdout","text":"Test product: White Gold Plated Princess\nCaption:\n‚ú® White Gold Plated Princess\n\nTimeless elegance. Stunning detail.\nLoved by 400+ customers. ‚≠ê 3/5\nüíé Just $9.99\n\nüëâ Grab yours ‚Äî link in bio!\n\n#ShopSmart #SmartShopping #Jewelry #JewelryLover #Accessories #GoldJewelry #Sale #ShopNow #NewArrival #Limited\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"tier2.run(num_posts=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:49:31.914681Z","iopub.execute_input":"2026-02-17T20:49:31.915494Z","iopub.status.idle":"2026-02-17T20:54:02.690573Z","shell.execute_reply.started":"2026-02-17T20:49:31.915463Z","shell.execute_reply":"2026-02-17T20:54:02.689902Z"}},"outputs":[{"name":"stdout","text":"\nTier 2: 3 posts\nPosts: 0/60 | Spent: $0.00/$500.0\n============================================================\n\nPost 1/3\n------------------------------------------------------------\nProduct: Rain Jacket Women Windbreaker Striped Climbing Rai\nPrice: $39.99 | Rating: 3.8‚≠ê\n\nCaption: üëó Rain Jacket Women Windbreaker Striped Climbing Raincoats\n\nStyle that turns heads.\n679+ reviews. ‚≠ê ...\nGenerating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daa8f394c564470f8f3ae506225cc830"}},"metadata":{}},{"name":"stdout","text":"Done: 2124.5KB\nUploaded to Cloudinary\nPosting to Instagram...\nContainer: 18133602226507887\n‚úÖ LIVE: https://www.instagram.com/p/18056680739400857/\n\nPost 2/3\n------------------------------------------------------------\nProduct: Mens Casual Slim Fit\nPrice: $15.99 | Rating: 2.1‚≠ê\n\nCaption: üî• Mens Casual Slim Fit\n\nUpgrade your wardrobe today.\n430+ reviews. ‚≠ê 2.1/5\nüí∞ Only $15.99\n\nüõí Shop now...\nGenerating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3ac7ccbe1434a20bd0225e05bbb55c5"}},"metadata":{}},{"name":"stdout","text":"Done: 1374.8KB\nUploaded to Cloudinary\nPosting to Instagram...\nContainer: 18133602349507887\n‚úÖ LIVE: https://www.instagram.com/p/18092639972286915/\n\nPost 3/3\n------------------------------------------------------------\nProduct: Silicon Power 256GB SSD 3D NAND A55 SLC Cache Perf\nPrice: $109.0 | Rating: 4.8‚≠ê\n\nCaption: ‚ö° Silicon Power 256GB SSD 3D NAND A55 SLC Cache Performance Boost SATA III 2.5\n\n3D NAND flash are ap...\nGenerating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfa77224747e472aa45efeb85d617a3d"}},"metadata":{}},{"name":"stdout","text":"Done: 1080.4KB\nUploaded to Cloudinary\nPosting to Instagram...\nContainer: 18133602418507887\n‚úÖ LIVE: https://www.instagram.com/p/18098487298930503/\n\n============================================================\nComplete: 3/3 posted\nPosts: 3/60 | Spent: $15.00/$500.0\n============================================================\n","output_type":"stream"}],"execution_count":24}]}